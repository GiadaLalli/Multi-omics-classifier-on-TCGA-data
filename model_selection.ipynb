{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import joblib\n",
    "import random\n",
    "import extra_funcs_TO\n",
    "import time\n",
    "import math\n",
    "#\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score, matthews_corrcoef\n",
    "#\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas.tools.plotting import table\n",
    "import subprocess\n",
    "%matplotlib inline\n",
    "import re\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import collections\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import scipy\n",
    "import csv\n",
    "import math\n",
    "from scipy import interp\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, auc\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import subprocess\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "import re\n",
    "import seaborn as sns\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### READ DATA\n",
    "rawData = pd.read_csv(\"mydata.csv\", low_memory=False)\n",
    "Hchain = rawData[\"sequence_alignment_aa_heavy\"]\n",
    "Lchain = rawData[\"sequence_alignment_aa_light\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    DIVMTQSPDSLAVSLGERATINCKSSQSVLYSSNNKNYLAWYQQKP...\n",
       "1    QSVLTQPPSVSAAPGQKVTISCSGSSSNIGNNYVSWYQQLPGTAPK...\n",
       "2    QSVLTQPPSASGTPGQRVTISCSGSSSNIGSNYVYWYQQLPGTAPK...\n",
       "3    EIVMTQSPATLSVSPGERATLSCRASQSVSSNLAWYQQKPGQAPRL...\n",
       "4    EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...\n",
       "Name: sequence_alignment_aa_light, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lchain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRUNCATE FOR DEV PURPOSES\n",
    "Hchain = Hchain[:1000]\n",
    "Lchain = Lchain[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SHUFFLE LCHAIN\n",
    "LchainShuf = Lchain.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALIGN DATA\n",
    "aligned = extra_funcs_TO.align_abs(Hchain, Lchain)\n",
    "alignedShuf = extra_funcs_TO.align_abs(Hchain, LchainShuf)\n",
    "alignedShuf = alignedShuf[~alignedShuf.isin([\"no seq\"])]\n",
    "alignedShuf.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENDCODE\n",
    "encoded = extra_funcs_TO.one_hot_encode(aligned.Hchain_align, aligned.Lchain_align)\n",
    "encodedShuf = extra_funcs_TO.one_hot_encode(alignedShuf.Hchain_align, alignedShuf.Lchain_align)\n",
    "\n",
    "### ADD LABEL\n",
    "encoded[\"pairing\"] = 1\n",
    "encodedShuf[\"pairing\"] = 0\n",
    "\n",
    "### MERGE FRAMES\n",
    "data = pd.concat([encoded, encodedShuf])\n",
    "\n",
    "### X, y\n",
    "X = data.drop(\"pairing\", axis=1)\n",
    "y = data[\"pairing\"]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data.drop(\"pairing\", axis=1), data[\"pairing\"], test_size=0.30,stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## MODEL SELECTION ##############\n",
    "inner_cv = 10\n",
    "gridSearchScorer = \"accuracy\"  #\"recall\"\n",
    "# CV for cross_validate scoring\n",
    "outer_cv = 10\n",
    "\n",
    "# Scoring metric for cross_validate\n",
    "scoring = {\"acc\":\"accuracy\",\n",
    "           \"b_acc\":\"balanced_accuracy\",\n",
    "           \"recall\":\"recall\",\n",
    "           \"precision\":\"precision\",\n",
    "           \"f1_micro\":\"f1_micro\",\n",
    "           \"f1_macro\":\"f1_macro\",\n",
    "           \"f1_weighted\":\"f1_weighted\",\n",
    "           \"roc_auc\":\"roc_auc\",\n",
    "           \"matthews_corrcoef\":make_scorer(matthews_corrcoef)}\n",
    "\n",
    "# Master Switch\n",
    "do_logisticRegression = True\n",
    "do_svc = False\n",
    "do_knn = False\n",
    "do_randomForest = False\n",
    "do_MLP = False\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if do_logisticRegression is True:\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    t0 = time.time()\n",
    "    print(\"\\nLogistic Regression \\t initiate ...\\n\")\n",
    "\n",
    "    # Construct Pipe\n",
    "    lr_clf = Pipeline([(\"classifier\", LogisticRegression(random_state=None))])\n",
    "    \n",
    "    # Define hyperparameter space\n",
    "    lr_param_grid = [{\"classifier__C\":[0.01,0.1,1],\n",
    "                   \"classifier__penalty\":[\"l2\"],\n",
    "                   \"classifier__solver\":[\"lbfgs\", \"newton-cg\"]}]\n",
    "\n",
    "    # Define hyperparameter space\n",
    "    lr_gs = GridSearchCV(lr_clf, lr_param_grid,\n",
    "                         cv = inner_cv,\n",
    "                         n_jobs=-1,\n",
    "                         scoring=gridSearchScorer,\n",
    "                         verbose=0)\n",
    "\n",
    "    # Get scoring metrics\n",
    "    print(\"Logistic Regression \\t scoring ...\\n\")\n",
    "    lr_score = cross_validate(lr_gs, X, y, cv=outer_cv, n_jobs=-1,\n",
    "                           scoring=scoring,\n",
    "                            verbose=0)\n",
    "    lr_score_df = pd.DataFrame(lr_score)\n",
    "\n",
    "    # Save as .csv\n",
    "    print(\"Logistic Regression \\t saving results ...\\n\")\n",
    "    lr_score_df.to_csv(\"results_LG_5000.csv\")\n",
    "\n",
    "    t1 = time.time() - t0\n",
    "    print(\"Logistic Regression \\t finished!!! (Time needed: {}) \\n\".format(t1))\n",
    "\n",
    "    ### SAVE MODEL\n",
    "\n",
    "    #joblib.dump(lr_gs.best_estimator_, \"results_LG.sav\")\n",
    "\n",
    "\n",
    "print(lr_score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVC \t initiate ...\n",
      "\n",
      "SVC \t scoring ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "t0 = time.time()\n",
    "print(\"\\nSVC \\t initiate ...\\n\")\n",
    "# Construct Pipe\n",
    "svc_clf = Pipeline([(\"classifier\", SVC(random_state=None))])\n",
    "# Define hyperparameter space\n",
    "svc_param_grid = [{\"classifier__C\": [0.01, 0.1, 1],\n",
    "                   \"classifier__kernel\":[\"poly\", \"rbf\"],\n",
    "                   \"classifier__degree\":range(2,5)}]\n",
    "# Define hyperparameter space\n",
    "svc_gs = GridSearchCV(svc_clf, svc_param_grid,\n",
    "                     cv = inner_cv,\n",
    "                     n_jobs=-1,\n",
    "                     scoring=gridSearchScorer,\n",
    "                     verbose=0)\n",
    "# svc_gs.fit(X_train, y_train)\n",
    "# svc_gs = svc_gs.cv_results_\n",
    "# print(\"Best estimator: {}\".format(svc_gs.best_estimator_[\"classifier\"]))\n",
    "# Get scoring metrics\n",
    "print(\"SVC \\t scoring ...\\n\")\n",
    "svc_score = cross_validate(svc_gs, X, y, cv=outer_cv, n_jobs=-1,\n",
    "                       scoring=scoring,\n",
    "                       verbose=0) \n",
    "svc_score_df = pd.DataFrame(svc_score)\n",
    "# Save as .csv\n",
    "print(\"SVC \\t saving results ...\\n\")\n",
    "svc_score_df.to_csv(\"results_SVC_2500.csv\")\n",
    "t1 = time.time() - t0\n",
    "print(\"SVC \\t finished!!! (Time needed: {}) \\n\".format(t1))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "t0 = time.time()\n",
    "print(\"\\nKNN \\t initiate ...\\n\")\n",
    "# Construct Pipe\n",
    "knn_clf = Pipeline([(\"classifier\", KNeighborsClassifier())])\n",
    "# Define hyperparameter space\n",
    "knn_param_grid = [{\"classifier__n_neighbors\":range(3,8),\n",
    "                   \"classifier__weights\":[\"uniform\", \"distance\"],\n",
    "                   \"classifier__leaf_size\":range(20,50,5),\n",
    "                   \"classifier__metric\": [\"minkowski\", \"euclidean\", \"manhattan\"]}]\n",
    "# Define hyperparameter space\n",
    "knn_gs = GridSearchCV(knn_clf, knn_param_grid,\n",
    "                     cv = inner_cv,\n",
    "                     n_jobs=-1,\n",
    "                     scoring=gridSearchScorer,\n",
    "                     verbose=0)\n",
    "# Get scoring metrics\n",
    "print(\"KNN \\t scoring ...\\n\")\n",
    "knn_score = cross_validate(knn_gs, X, y,\n",
    "                            cv=outer_cv, n_jobs=-1,\n",
    "                            scoring=scoring,\n",
    "                            verbose=0)\n",
    "knn_score_df = pd.DataFrame(knn_score)\n",
    "# Save as .csv\n",
    "print(\"KNN \\t saving results ...\\n\")\n",
    "knn_score_df.to_csv(\"results_KNN_5000.csv\")\n",
    "t1 = time.time() - t0\n",
    "print(\"KNN \\t finished!!! (Time needed: {}) \\n\".format(t1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "t0 = time.time()\n",
    "print(\"\\nRandom Forest \\t initiate ...\\n\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Construct Pipe\n",
    "rf_clf = Pipeline([(\"classifier\", RandomForestClassifier(random_state=None))])\n",
    "# Define hyperparameter space\n",
    "rf_param_grid = [{\"classifier__n_estimators\":range(100,550,50),\n",
    "                   \"classifier__criterion\":[\"gini\", \"entropy\"],\n",
    "                   \"classifier__min_samples_split\":range(2,8,1)}]\n",
    "# Define hyperparameter space\n",
    "rf_gs = GridSearchCV(rf_clf, rf_param_grid,\n",
    "                     cv = inner_cv,\n",
    "                     n_jobs=-1,\n",
    "                     scoring=gridSearchScorer)\n",
    "# Get scoring metrics\n",
    "print(\"Random Forest \\t scoring ...\\n\")\n",
    "rf_score = cross_validate(rf_gs, X, y,\n",
    "                           cv=outer_cv,\n",
    "                           n_jobs=-1,\n",
    "                           scoring=scoring,\n",
    "                           verbose=0)\n",
    "rf_score_df = pd.DataFrame(rf_score)\n",
    "# Save as .csv\n",
    "print(\"Random Forest \\t saving results ...\\n\")\n",
    "rf_score_df.to_csv(\"results_RF_5000.csv\")\n",
    "t1 = time.time() - t0\n",
    "print(\"Random Forest \\t finished!!! (Time needed: {}) \\n\".format(t1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "res = pd.read_csv(\"results_RF_1000.csv\", low_memory=False)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "res = pd.read_csv(\"results_SVC_1000.csv\", low_memory=False)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "res = pd.read_csv(\"results_KNN_1000.csv\", low_memory=False)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "res = pd.read_csv(\"results_LG_1000.csv\", low_memory=False)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(svc_clf, \"finalized_model_1000.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "33a9b5d4a72ad3daa12ad49f88102a0762f437a5adc51e3dc9ab9f20a66dfa27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
