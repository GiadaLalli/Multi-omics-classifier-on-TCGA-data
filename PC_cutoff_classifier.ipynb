{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import subprocess\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import collections\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import scipy\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import joblib\n",
    "import random\n",
    "import extra_funcs_TO\n",
    "\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from pandas.tools.plotting import table\n",
    "from scipy import interp\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_blobs, make_classification\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, VarianceThreshold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold, GridSearchCV, LeaveOneOut, train_test_split, StratifiedShuffleSplit, cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, auc, roc_curve, precision_recall_curve, f1_score, classification_report, make_scorer, balanced_accuracy_score, roc_auc_score, matthews_corrcoef\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset=pd.read_csv (\"clintab_GMQL/gencode.gene.info.v22.tsv\", delimiter='\\t')\n",
    "gruppo=dset.groupby(['gene_type'])\n",
    "proteingroup=gruppo.get_group('protein_coding')\n",
    "lista1=set(proteingroup['gene_id'])\n",
    "#len(proteingroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_rna_res=pd.read_csv(\"clintab_GMQL/gene_exprs/res/res_new.csv\", delimiter='\\t')\n",
    "dset_rna_senl=pd.read_csv(\"clintab_GMQL/gene_exprs/sl_32/sl_new.csv\", delimiter='\\t')\n",
    "dset_rna_sens=pd.read_csv(\"clintab_GMQL/gene_exprs/ss_32/ss_new.csv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_res = dset_rna_res[dset_rna_res.ensemble_id.isin(lista1)]\n",
    "protein_coding_res=pd.DataFrame(dset_res)\n",
    "protein_coding_res['genes'] = protein_coding_res['ensemble_id']+'-'+ protein_coding_res['gene_symbol']\n",
    "#protein_coding_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_senl = dset_rna_senl[dset_rna_senl.ensemble_id.isin(lista1)]\n",
    "protein_coding_senl=pd.DataFrame(dset_senl)\n",
    "protein_coding_senl['genes'] = protein_coding_senl['ensemble_id']+'-'+ protein_coding_senl['gene_symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_sens = dset_rna_sens[dset_rna_sens.ensemble_id.isin(lista1)]\n",
    "protein_coding_sens=pd.DataFrame(dset_sens)\n",
    "protein_coding_sens['genes'] = protein_coding_sens['ensemble_id']+'-'+ protein_coding_sens['gene_symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 19814)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resdf=protein_coding_res.pivot(index=\"patient\", columns=\"genes\", values=\"fpkm\")\n",
    "genes = resdf.columns.tolist()\n",
    "#resdf.head()\n",
    "resdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 19814)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senldf=protein_coding_senl.pivot(index=\"patient\", columns=\"genes\", values=\"fpkm\")\n",
    "senldf = senldf[genes]\n",
    "#senldf.head()\n",
    "senldf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 19814)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensdf=protein_coding_sens.pivot(index=\"patient\", columns=\"genes\", values=\"fpkm\")\n",
    "sensdf = sensdf[genes]\n",
    "#sensdf.head()\n",
    "sensdf.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "resdf['label']=np.ones(len(resdf.index))\n",
    "sensdf['label']=np.zeros(len(sensdf.index))\n",
    "senldf['label']=np.ones(len(senldf.index))\n",
    "#tot=pd.concat([resdf, senldf])\n",
    "tot=pd.concat([sensdf, resdf])\n",
    "#tot=pd.concat([sensdf, senldf])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X=tot[tot.columns[:-1]].values\n",
    "y=tot[tot.columns[-1]].values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c_matrix=confusion_matrix(y_test, y_pred)\n",
    "c_matrix"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#kf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=36851234)\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "recall=[]\n",
    "precision=[]\n",
    "accuracy=[]\n",
    "fscore=[]\n",
    "scores=['true_sens', 'false_senl', 'true_senl', 'false_sens', 'accuracy', 'precision', 'recall', 'f1_score']\n",
    "performance=pd.DataFrame(index=np.arange(10), columns=scores)\n",
    "i=0\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    '''X=pd.DataFrame(x_train, columns=features)\n",
    "    model= RandomForestClassifier(n_estimators=200, max_depth=15, class_weight='balanced')\n",
    "    model.fit(X,y_train)\n",
    "    f=feat_importances.nlargest(15).index\n",
    "    x_train=X[f].values\n",
    "    X_t=pd.DataFrame(x_test, columns=features)\n",
    "    x_test=X_t[f]'''\n",
    "    \n",
    "    print('real')\n",
    "    print(y_test)\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=200, max_depth=15, class_weight='balanced')\n",
    "    #clf=KNeighborsClassifier(n_neighbors=3, metric='manhattan')\n",
    "    #clf = AdaBoostClassifier(n_estimators=200, base_estimator=DecisionTreeClassifier(max_depth=5),random_state=0)\n",
    "    #clf=LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
    "    #clf = svm.SVC(kernel='rbf', C=100, probability=True, gamma = 0.0001, class_weight='balanced', random_state=42)\n",
    "    \n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred=clf.predict(x_test)\n",
    "    print('predicted')\n",
    "    print(y_pred)\n",
    "    recall.append(recall_score(y_test, y_pred))\n",
    "    precision.append(precision_score(y_test, y_pred))\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    fscore.append(f1_score(y_test, y_pred))\n",
    "    performance.iloc[i]['accuracy']=accuracy_score(y_test, y_pred)\n",
    "    performance.iloc[i]['precision']=precision_score(y_test, y_pred)\n",
    "    performance.iloc[i]['recall']=recall_score(y_test, y_pred)\n",
    "    performance.iloc[i]['f1_score']=f1_score(y_test, y_pred)\n",
    "    c_matrix=confusion_matrix(y_test, y_pred)\n",
    "    performance.iloc[i]['true_sens']=c_matrix[0][0]\n",
    "    performance.iloc[i]['false_sens']=c_matrix[1][0]\n",
    "    performance.iloc[i]['true_senl']=c_matrix[1][1]\n",
    "    performance.iloc[i]['false_senl']=c_matrix[0][1]\n",
    "    print (i)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('Average precision: ', np.mean(precision))\n",
    "print('Average recall: ', np.mean(recall))\n",
    "print('Average accuracy: ', np.mean(accuracy))\n",
    "print('Average f_score: ', np.mean(fscore))\n",
    "\n",
    "print('Standard_deviation precision: ', np.std(precision))\n",
    "print('Standard_deviation recall: ', np.std(recall))\n",
    "print('Standard_deviation accuracy: ', np.std(accuracy))\n",
    "print('Standard_deviation f_score: ', np.std(fscore))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_median = resdf.median(0)\n",
    "senldf_median = senldf.median(0)\n",
    "sensdf_median = sensdf.median(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19814,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resdf_median.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19814 19814 19814\n"
     ]
    }
   ],
   "source": [
    "print(len(resdf_median), len(senldf_median), len(sensdf_median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19814/19814 [00:07<00:00, 2639.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>sensitive_long_median</th>\n",
       "      <th>sensitive_short_median</th>\n",
       "      <th>mannwhiteney_pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000000003.13-TSPAN6</td>\n",
       "      <td>18.905782</td>\n",
       "      <td>15.924936</td>\n",
       "      <td>0.044214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000000005.5-TNMD</td>\n",
       "      <td>0.074047</td>\n",
       "      <td>0.067985</td>\n",
       "      <td>0.330315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000000419.11-DPM1</td>\n",
       "      <td>41.232656</td>\n",
       "      <td>43.144585</td>\n",
       "      <td>0.475980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000000457.12-SCYL3</td>\n",
       "      <td>1.890405</td>\n",
       "      <td>2.014650</td>\n",
       "      <td>0.394546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000000460.15-C1orf112</td>\n",
       "      <td>1.703900</td>\n",
       "      <td>1.640842</td>\n",
       "      <td>0.470225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          gene  sensitive_long_median  sensitive_short_median  \\\n",
       "0    ENSG00000000003.13-TSPAN6              18.905782               15.924936   \n",
       "1       ENSG00000000005.5-TNMD               0.074047                0.067985   \n",
       "2      ENSG00000000419.11-DPM1              41.232656               43.144585   \n",
       "3     ENSG00000000457.12-SCYL3               1.890405                2.014650   \n",
       "4  ENSG00000000460.15-C1orf112               1.703900                1.640842   \n",
       "\n",
       "   mannwhiteney_pvalue  \n",
       "0             0.044214  \n",
       "1             0.330315  \n",
       "2             0.475980  \n",
       "3             0.394546  \n",
       "4             0.470225  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalues = []\n",
    "for gene in tqdm(genes):\n",
    "    try:\n",
    "        gene_pvalue = scipy.stats.mannwhitneyu(senldf[gene],sensdf[gene]).pvalue\n",
    "    except Exception:\n",
    "        gene_pvalue = 1\n",
    "    pvalues.append(gene_pvalue)\n",
    "       \n",
    "pvalues = pd.DataFrame({\n",
    "    \"gene\": genes,\n",
    "    #\"resistant_median\": resdf_median.values,\n",
    "    \"sensitive_long_median\": senldf_median.values,\n",
    "    \"sensitive_short_median\": sensdf_median.values,\n",
    "    \"mannwhiteney_pvalue\": pvalues\n",
    "})\n",
    "\n",
    "pvalues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.0006\n",
    "min_median_sum = 0\n",
    "\n",
    "significant_genes = pvalues[(pvalues.mannwhiteney_pvalue < threshold)].copy()# & \n",
    "                           # (pvalues.sensitive_short_median + pvalues.sensitive_long_median > min_median_sum)].copy()\n",
    "#significant_genes[\"median_difference\"] = (significant_genes.resistant_median - significant_genes.sensitive_short_median).abs()\n",
    "significant_genes = significant_genes.sort_values(\"mannwhiteney_pvalue\", ascending=True)\n",
    "print(significant_genes.shape[0])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "threshold = 0.0006\n",
    "min_median_diff = 0\n",
    "\n",
    "significant_genes = pvalues[(pvalues.mannwhiteney_pvalue < threshold) & \n",
    "                            ((pvalues.sensitive_short_median - pvalues.sensitive_long_median).abs() > min_median_diff)].copy()\n",
    "#significant_genes[\"median_sum\"] = (significant_genes.resistant_median + significant_genes.sensitive_short_median).copy()\n",
    "significant_genes = significant_genes.sort_values(\"mannwhiteney_pvalue\", ascending=True)\n",
    "print(significant_genes.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[]\n",
    "\n",
    "for x in [\"-\".join(x.strip().split(\"-\")[1:])  for x in (significant_genes['gene'])]:\n",
    "    names.append(x)   \n",
    "    \n",
    "significant_genes['gene_symbol']=names\n",
    "significant_genes=pd.DataFrame(significant_genes)\n",
    "#significant_genes.to_csv('giada/sl_ss_6.csv', sep=',', header=True, index=False)\n",
    "#significant_genes.to_csv('significant_genes_res_ss.csv', sep=',', header=True, index=False)\n",
    "#significant_genes.to_csv('significant_genes_sl_ss.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "listageni=significant_genes['gene_symbol'].values\n",
    "listageni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_genes_pc=pd.read_csv('common_genes/common_genes_total_us.csv', sep=';')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "column=pvalues['gene']\n",
    "column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes=(common_genes_pc['ensemble_id_us'])\n",
    "genes=genes.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ENSG00000137393.9-RNF144B\n",
       "1     ENSG00000134504.11-KCTD1\n",
       "2       ENSG00000137364.4-TPMT\n",
       "3    ENSG00000090520.9-DNAJB11\n",
       "4     ENSG00000177383.4-MAGEF1\n",
       "Name: ensemble_id_us, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column=genes['ensemble_id_us']\n",
    "column.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "column=protein_coding_res['genes']\n",
    "column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lalli/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60, 123)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_selected=resdf[column]\n",
    "res_selected[\"label\"]=1\n",
    "res_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lalli/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(34, 123)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senl_selected=senldf[column]\n",
    "senl_selected[\"label\"]=1\n",
    "senl_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lalli/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(107, 123)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens_selected=sensdf[column]\n",
    "sens_selected[\"label\"]=0\n",
    "sens_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenated=pd.concat([res_selected, senl_selected])\n",
    "#concatenated=pd.concat([res_selected, sens_selected])\n",
    "concatenated=pd.concat([senl_selected, sens_selected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=concatenated[concatenated.columns[:-1]].values\n",
    "y=concatenated[concatenated.columns[-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_PCA(data, features, labels, i, j):\n",
    "    #x = data.loc[:, features].values\n",
    "    x = StandardScaler().fit_transform(data)\n",
    "    \n",
    "    pca= PCA(n_components=3)\n",
    "    p_comp=pca.fit_transform(x)\n",
    "    #p_comp = TSNE(n_components=2, perplexity=70, n_iter=2500).fit_transform(x)\n",
    "    p_comp=p_comp[:, [i,j]]\n",
    "\n",
    "    principalDf = pd.DataFrame(data = p_comp\n",
    "             , columns = ['principal component '+str(i), 'principal component '+str(j)])\n",
    "    finalDf= pd.concat([principalDf, pd.Series(labels)], axis=1)\n",
    "    \n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    ax = fig.add_subplot(1,1,1) \n",
    "    ax.set_xlabel('Principal Component '+str(i+1), fontsize = 15)\n",
    "    ax.set_ylabel('Principal Component '+str(j+1), fontsize = 15)\n",
    "    ax.set_title('2 Component PCA', fontsize = 20)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    targets = ['Resistant', 'Sensitive_short']\n",
    "    colors = ['b', 'r']\n",
    "    for target, color in zip(targets,colors):\n",
    "        t=0\n",
    "        if target == 'Resistant':\n",
    "            t=1\n",
    "        #if target == 'Sensitive_long':\n",
    "         #   t=2\n",
    "        indicesToKeep = finalDf[0] == t\n",
    "        ax.scatter(finalDf.loc[indicesToKeep, 'principal component '+str(i)]\n",
    "                   , finalDf.loc[indicesToKeep, 'principal component '+str(j)]\n",
    "                   , c = color\n",
    "                   , s = 50)\n",
    "    ax.legend(targets)\n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_PCA(X, concatenated.columns, y, 0, 2)\n",
    "#plt.savefig('my_PCA_res_sens_12.png')\n",
    "my_PCA"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "precision=[]\n",
    "recall=[]\n",
    "\n",
    "#loo = LeaveOneOut()\n",
    "#loo.get_n_splits(X)\n",
    "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=20, random_state=36851234)\n",
    "for train_index, test_index in (rskf.split(X, y)) :\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "clf = svm.SVC(kernel='rbf', class_weight='balanced')\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict=clf.predict(X_test)\n",
    "    \n",
    "    precision.append(precision_score(y_test, y_predict))\n",
    "    recall.append(recall_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real\n",
      "[1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predicted\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "0\n",
      "real\n",
      "[1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lalli/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lalli/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "1\n",
      "real\n",
      "[1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predicted\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "2\n",
      "real\n",
      "[1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predicted\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "3\n",
      "real\n",
      "[1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lalli/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lalli/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "4\n",
      "real\n",
      "[1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predicted\n",
      "[1 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "5\n",
      "real\n",
      "[1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predicted\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "6\n",
      "real\n",
      "[1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "predicted\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "7\n",
      "real\n",
      "[1 1 1 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lalli/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lalli/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted\n",
      "[1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "8\n",
      "real\n",
      "[1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "predicted\n",
      "[1 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#kf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=36851234)\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "recall=[]\n",
    "precision=[]\n",
    "accuracy=[]\n",
    "fscore=[]\n",
    "scores=['true_sens', 'false_senl', 'true_senl', 'false_sens', 'accuracy', 'precision', 'recall']\n",
    "performance=pd.DataFrame(index=np.arange(10), columns=scores)\n",
    "i=0\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    '''X=pd.DataFrame(x_train, columns=features)\n",
    "    model= RandomForestClassifier(n_estimators=200, max_depth=15, class_weight='balanced')\n",
    "    model.fit(X,y_train)\n",
    "    f=feat_importances.nlargest(15).index\n",
    "    x_train=X[f].values\n",
    "    X_t=pd.DataFrame(x_test, columns=features)\n",
    "    x_test=X_t[f]'''\n",
    "    \n",
    "    print('real')\n",
    "    print(y_test)\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=200, max_depth=15, class_weight='balanced')\n",
    "    #clf=KNeighborsClassifier(n_neighbors=3, metric='manhattan')\n",
    "    #clf = AdaBoostClassifier(n_estimators=200, base_estimator=DecisionTreeClassifier(max_depth=5),random_state=0)\n",
    "    #clf=LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
    "    #clf = svm.SVC(kernel='rbf', C=100, probability=True, gamma = 0.0001, class_weight='balanced', random_state=42)\n",
    "    \n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred=clf.predict(x_test)\n",
    "    print('predicted')\n",
    "    print(y_pred)\n",
    "    recall.append(recall_score(y_test, y_pred))\n",
    "    precision.append(precision_score(y_test, y_pred))\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    performance.iloc[i]['accuracy']=accuracy_score(y_test, y_pred)\n",
    "    performance.iloc[i]['precision']=precision_score(y_test, y_pred)\n",
    "    performance.iloc[i]['recall']=recall_score(y_test, y_pred)\n",
    "    c_matrix=confusion_matrix(y_test, y_pred)\n",
    "    performance.iloc[i]['true_sens']=c_matrix[0][0]\n",
    "    performance.iloc[i]['false_sens']=c_matrix[1][0]\n",
    "    performance.iloc[i]['true_senl']=c_matrix[1][1]\n",
    "    performance.iloc[i]['false_senl']=c_matrix[0][1]\n",
    "    print (i)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision:  0.5\n",
      "Average recall:  0.2416666666666667\n",
      "Average accuracy:  0.7941025641025641\n",
      "Standard_deviation precision:  0.4472135954999579\n",
      "Standard_deviation recall:  0.225\n",
      "Standard_deviation accuracy:  0.0655504612195348\n"
     ]
    }
   ],
   "source": [
    "print('Average precision: ', np.mean(precision))\n",
    "print('Average recall: ', np.mean(recall))\n",
    "print('Average accuracy: ', np.mean(accuracy))\n",
    "print('Standard_deviation precision: ', np.std(precision))\n",
    "print('Standard_deviation recall: ', np.std(recall))\n",
    "print('Standard_deviation accuracy: ', np.std(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_sens</th>\n",
       "      <th>false_senl</th>\n",
       "      <th>true_senl</th>\n",
       "      <th>false_sens</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  true_sens false_senl true_senl false_sens  accuracy precision    recall\n",
       "0        11          0         0          4  0.733333         0         0\n",
       "1        11          0         2          2  0.866667         1       0.5\n",
       "2        11          0         1          3       0.8         1      0.25\n",
       "3        11          0         0          4  0.733333         0         0\n",
       "4        11          0         1          2  0.857143         1  0.333333\n",
       "5        11          0         2          1  0.928571         1  0.666667\n",
       "6        10          1         0          3  0.714286         0         0\n",
       "7        10          0         0          3  0.769231         0         0\n",
       "8         9          1         1          2  0.769231       0.5  0.333333\n",
       "9         9          1         1          2  0.769231       0.5  0.333333"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "classifier = RandomForestClassifier(n_estimators=200, max_depth=15, class_weight='balanced')\n",
    "#classifier = AdaBoostClassifier(n_estimators=200, base_estimator=DecisionTreeClassifier(max_depth=5),random_state=0)\n",
    "#classifier = svm.SVC(kernel='rbf', C=100, probability=True, gamma = 0.0001, class_weight='balanced', random_state=42)\n",
    "#classifier=KNeighborsClassifier(n_neighbors=3, metric='manhattan')\n",
    "#classifier= LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=36851234)\n",
    "\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(10,10))\n",
    "i = 0\n",
    "for train, test in cv.split(X, y):\n",
    "    probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "             label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "    i += 1\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve SenL vs SenS')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "#plt.savefig('ROC_Res_vs_SenL_RF.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=36851234)\n",
    "y_real = []\n",
    "y_proba = []\n",
    "#predictor= RandomForestClassifier(n_estimators=200, max_depth=15, class_weight='balanced')\n",
    "#predictor = AdaBoostClassifier(n_estimators=200, base_estimator=DecisionTreeClassifier(max_depth=5),random_state=0)\n",
    "predictor = svm.SVC(kernel='rbf', C=100, probability=True, gamma = 0.0001, class_weight='balanced', random_state=42)\n",
    "#predictor = KNeighborsClassifier(n_neighbors=3, metric='manhattan')\n",
    "#predictor = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=36851234)\n",
    "\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(10,10))\n",
    "i = 0\n",
    "for train, test in cv.split(X, y):\n",
    "    probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "             label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "    i += 1\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "#plt.title('ROC curve Res vs Senl')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "plt.savefig('ROC_Res_vs_SenS.png')\n",
    "#predictor = AdaBoostClassifier(n_estimators=200, base_estimator=DecisionTreeClassifier(max_depth=5),random_state=0)\n",
    "precision_array = []\n",
    "threshold_array=[]\n",
    "recall_array = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(10,10))\n",
    "for i, (train_index, test_index) in enumerate(k_fold.split(X, y)):\n",
    "    Xtrain, Xtest = X[train_index], X[test_index]\n",
    "    ytrain, ytest = y[train_index], y[test_index]\n",
    "    predictor.fit(Xtrain, ytrain)\n",
    "    pred_proba = predictor.predict_proba(Xtest)\n",
    "    precision_fold, recall_fold, thresh = precision_recall_curve(ytest, pred_proba[:,1])\n",
    "    precision_fold, recall_fold, thresh = precision_fold[::-1], recall_fold[::-1], thresh[::-1]  # reverse order of results\n",
    "    thresh = np.insert(thresh, 0, 1.0)\n",
    "    precision_array = interp(recall_array, recall_fold, precision_fold)\n",
    "    threshold_array = interp(recall_array, recall_fold, thresh)\n",
    "    pr_auc = auc(recall_array, precision_array)\n",
    "\n",
    "    lab_fold = 'Fold %d AUC=%.4f' % (i+1, pr_auc)\n",
    "    plt.plot(recall_fold, precision_fold, alpha=0.3, label=lab_fold)\n",
    "    y_real.append(ytest)\n",
    "    y_proba.append(pred_proba[:,1])\n",
    "    \n",
    "y_real = np.concatenate(y_real)\n",
    "y_proba = np.concatenate(y_proba)\n",
    "precision, recall, thr = precision_recall_curve(y_real, y_proba)\n",
    "lab = 'Overall AUC=%.4f' % (auc(recall, precision))\n",
    "\n",
    "plt.plot(recall, precision, lw=2,color='red', label=lab)\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "\n",
    "mean_precision = np.mean(precision_array)\n",
    "std_precision = np.std(precision_array)\n",
    "plt.fill_between(recall, precision + std_precision, precision - std_precision, alpha=0.3, linewidth=0, color='grey')\n",
    "#plt.show()\n",
    "#plt.title('PR curve Res vs SenS')\n",
    "#plt.savefig('PR curve Res vs Senl_RF.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_senl=pd.read_csv(\"geni_Res_SenL.csv\", delimiter=',')\n",
    "res_sens=pd.read_csv(\"geni_Res_SenS.csv\", delimiter=',')\n",
    "senl_sens=pd.read_csv(\"geni_SenL_SenS.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_senl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_res_senl=pd.DataFrame(res_senl['ensemble_id'])\n",
    "lista_res_sens=pd.DataFrame(res_sens['ensemble_id'])\n",
    "lista_senl_sens=pd.DataFrame(senl_sens['ensemble_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated=pd.concat([lista_res_senl, lista_res_sens, lista_senl_sens])\n",
    "tutti_geni=concatenated.drop_duplicates()\n",
    "tutti_geni.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[]\n",
    "\n",
    "for x in [\"-\".join(x.strip().split(\"-\")[1:])  for x in (tutti_geni['ensemble_id'])]:\n",
    "    names.append(x)   \n",
    "    \n",
    "tutti_geni['gene_names']=names\n",
    "tutti_geni=pd.DataFrame(tutti_geni)\n",
    "tutti_geni.to_csv('common_genes_total.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
